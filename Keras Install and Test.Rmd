---
title: "Keras"
author: "Mike"
date: "2/25/2020"
output: 
  html_document:
    toc: TRUE
    keep_md: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}

#https://towardsdatascience.com/how-to-implement-deep-learning-in-r-using-keras-and-tensorflow-82d135ae4889

library(keras)
library(tensorflow)
#Install above libraries, restart R, then for first time:
#install_keras()

# Loading sample dataset (100mb images)
cifar <- dataset_cifar10()

View(cifar)
#TRAINING DATA
train_x<-cifar$train$x/255
#convert a vector class to binary class matrix
#converting the target variable to one hot encoded vectors using #keras inbuilt function 'to_categorical()
train_y<-to_categorical(cifar$train$y,num_classes = 10)

#TEST DATA
test_x<-cifar$test$x/255
test_y<-to_categorical(cifar$test$y,num_classes=10) 
#checking the dimentions
dim(train_x) 
cat("No of training samples\t",dim(train_x)[[1]],"\tNo of test samples\t",dim(test_x)[[1]])


```

```{r, include=FALSE}

#a linear stack of layers
model<-keras_model_sequential()
#configuring the Model
model %>%  
#defining a 2-D convolution layer: This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is TRUE, a bias vector is created and added to the outputs Finally, if activation is not NULL, it is applied to the outputs as well. When using this layer as the first layer in a model, provide the keyword argument input_shape (list of integers, does not include the sample axis), e.g. input_shape=c(128, 128, 3) for 128x128 RGB pictures in data_format="channels_last".
# https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/
    
layer_conv_2d(filter=32,kernel_size=c(3,3),padding="same", input_shape=c(32,32,3) ) %>%  
layer_activation("relu") %>%  
#another 2-D convolution layer
  
layer_conv_2d(filter=32 ,kernel_size=c(3,3))  %>%  layer_activation("relu") %>%
#Defining a Pooling layer which reduces the dimentions of the #features map and reduces the computational complexity of the model
layer_max_pooling_2d(pool_size=c(2,2)) %>%  
#dropout layer to avoid overfitting
layer_dropout(0.25) %>%
layer_conv_2d(filter=32 , kernel_size=c(3,3),padding="same") %>% layer_activation("relu") %>%  layer_conv_2d(filter=32,kernel_size=c(3,3) ) %>%  layer_activation("relu") %>%  
layer_max_pooling_2d(pool_size=c(2,2)) %>%  
layer_dropout(0.25) %>%
#flatten the input  
layer_flatten() %>%  
layer_dense(512) %>%  
layer_activation("relu") %>%  
layer_dropout(0.5) %>%  
#output layer-10 classes-10 units  
layer_dense(10) %>%  
#applying softmax nonlinear activation function to the output layer #to calculate cross-entropy  
layer_activation("softmax") 
#for computing Probabilities of classes-"logit(log probabilities)

```

# Model Optimizer
```{r, include = FALSE}


#defining the type of optimizer-ADAM-Adaptive Momentum Estimation
opt<-optimizer_adam( lr= 0.0001 , decay = 1e-6 )
#lr-learning rate , decay - learning rate decay over each update

model %>%
 compile(loss="categorical_crossentropy",
 optimizer=opt,metrics = "accuracy")
#Summary of the Model and its Architecture
summary(model)

```

# Model Training
```{r, include = FALSE}
#TRAINING PROCESS OF THE MODEL
data_augmentation <- TRUE  
if(!data_augmentation) {  
model %>% fit( train_x,train_y ,batch_size=32,
               epochs=80,validation_data = list(test_x, test_y),
               shuffle=TRUE)
}
  else {  
#Generating images
  
gen_images <- image_data_generator(featurewise_center = TRUE,
      featurewise_std_normalization = TRUE,
      rotation_range = 20,
      width_shift_range = 0.30,
      height_shift_range = 0.30,
      horizontal_flip = TRUE  )
#Fit image data generator internal statistics to some sample data
gen_images %>% fit_image_data_generator(train_x)
#Generates batches of augmented/normalized data from image data and #labels to visually see the generated images by the Model
model %>% fit_generator(
     flow_images_from_data(train_x, train_y,gen_images,
     batch_size=32,save_to_dir="F:/PROJECTS/CNNcifarimages/"),
     steps_per_epoch=as.integer(50000/32),epochs = 80,
     validation_data = list(test_x, test_y) )
}
#use save_to_dir argument to specify the directory to save the #images generated by the Model and to visually check the Model's #output and ability to classify images.

```
